import os
import logging
import uuid
from typing import List, Literal
from fastapi import FastAPI, HTTPException, Request, status
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from groq import Groq
from dotenv import load_dotenv

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
load_dotenv()
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("BekzhanTravelAPI")

app = FastAPI(title="Kazakhstan Travel AI by Bekzhan")

# “ö–∞—É—ñ–ø—Å—ñ–∑–¥—ñ–∫ –±–∞–ø—Ç–∞—É–ª–∞—Ä—ã
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], # –ü—Ä–æ–¥–∞–∫—à–Ω–¥–∞ –Ω–∞“õ—Ç—ã –¥–æ–º–µ–Ω–¥—ñ –∂–∞–∑—É –∫–µ—Ä–µ–∫
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Groq –∫–ª–∏–µ–Ω—Ç—ñ
try:
    GROQ_API_KEY = os.getenv("GROQ_API_KEY", "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")
    client = Groq(api_key=GROQ_API_KEY)
except Exception as e:
    logger.error(f"API Key Error: {e}")

class Message(BaseModel):
    role: Literal["user", "assistant"]
    content: str = Field(..., min_length=1, max_length=2000)

class ChatRequest(BaseModel):
    history: List[Message]

# –°–ï–ù–Ü“¢ –ü–†”®–§–ï–°–°–ò–û–ù–ê–õ–î–´ –ü–†–û–ú–ü–¢–´“¢
SYSTEM_PROMPT = {
    "role": "system",
    "content": (
        "SYSTEM ROLE: Kazakhstan Travel Assistant\n"
        "You are a professional AI travel assistant specialized exclusively in Kazakhstan.\n"
        "Your goal is to provide practical, structured, and realistic travel guidance.\n"
        "Rules: Reply in user's language. Never provide fictional places. Be neutral and practical.\n"
        "Structure: üìç Overview, üóì Duration, üó∫ Itinerary, üí∞ Budget, üöó Transport, üçΩ Food, üì∏ Photo Spots, ‚ö† Safety, üå¶ Best Season."
    )
}

@app.post("/api/chat")
async def chat_handler(request: ChatRequest):
    req_id = str(uuid.uuid4())[:8]
    logger.info(f"[{req_id}] Processing request...")
    
    try:
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç—Ç—ñ —à–µ–∫—Ç–µ—É (Token optimization)
        trimmed_history = request.history[-10:]
        messages = [SYSTEM_PROMPT] + [m.model_dump() for m in trimmed_history]

        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=messages,
            temperature=0.35, # –ì–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏—è–Ω—ã –∞–∑–∞–π—Ç—É
            max_tokens=2048,
            top_p=1
        )
        
        response_content = completion.choices[0].message.content
        if not response_content:
            raise ValueError("AI returned empty string")

        logger.info(f"[{req_id}] Success.")
        return {"response": response_content}

    except Exception as e:
        logger.error(f"[{req_id}] Error: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="–°–µ—Ä–≤–µ—Ä–¥–µ –∞“õ–∞—É —à—ã“õ—Ç—ã. “ö–∞–π—Ç–∞ –±–∞–π“õ–∞–ø –∫”©—Ä—ñ“£—ñ–∑."
        )

@app.get("/health")
def health():
    return {"status": "online", "developer": "Bekzhan"}
