from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import os
import json
from groq import Groq

app = FastAPI()

# Frontend (Vercel) —Å–µ—Ä–≤–µ—Ä—ñ–Ω–µ —Ä“±“õ—Å–∞—Ç –±–µ—Ä—É
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Groq –ö–ª–∏–µ–Ω—Ç—ñ - –°–µ–Ω—ñ“£ API –∫—ñ–ª—Ç—ñ“£
client = Groq(api_key="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")

class ChatRequest(BaseModel):
    message: str

# 1. –°–µ—Ä–≤–µ—Ä–¥—ñ“£ —Ç—ñ—Ä—ñ –µ–∫–µ–Ω—ñ–Ω —Ç–µ–∫—Å–µ—Ä—É
@app.get("/")
async def root():
    return {"status": "active", "agent": "Kazakhstan Travel AI"}

# 2. –ñ–µ—Ä–≥—ñ–ª—ñ–∫—Ç—ñ –¥–µ—Ä–µ–∫—Ç–µ—Ä “õ–æ—Ä—ã–Ω –∞–ª—É (places.json)
@app.get("/api/places")
async def get_places():
    try:
        file_path = os.path.join(os.path.dirname(__file__), "places.json")
        with open(file_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        return {"error": "File not found", "details": str(e)}

# 3. –ï“¢ –ú–ê“¢–´–ó–î–´–°–´: –ê“õ—ã–ª–¥—ã –ò–ò –ß–∞—Ç
@app.post("/api/chat")
async def chat(request: ChatRequest):
    try:
        # –°–ï–ù –ë–ï–†–ì–ï–ù –ö”ò–°–Ü–ë–ò SYSTEM ROLE
        system_instructions = """
        SYSTEM ROLE: Kazakhstan Travel Assistant
        You are a professional AI travel assistant specialized exclusively in Kazakhstan.
        Your goal is to provide practical, structured, and realistic travel guidance.

        CORE RULES:
        1. Always detect and reply in the user's language (Kazakh, Russian, or English).
        2. If key information is missing (city, duration, budget), ask a short clarifying question.
        3. Structure travel plans with: üìç Overview, üóì Duration, üó∫ Itinerary, üí∞ Budget, üöó Transport, üçΩ Food, üì∏ Photo Spots.
        4. Never provide fictional places.
        5. Stay neutral, informative, and practical. No long-winded philosophy.
        """

        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[
                {"role": "system", "content": system_instructions},
                {"role": "user", "content": request.message}
            ],
            temperature=0.7, # –®—ã“ì–∞—Ä–º–∞—à—ã–ª—ã“õ –ø–µ–Ω –Ω–∞“õ—Ç—ã–ª—ã“õ —Ç–µ–ø–µ-—Ç–µ“£–¥—ñ–≥—ñ
            max_tokens=2048
        )
        
        return {"response": completion.choices[0].message.content}
    
    except Exception as e:
        print(f"Error: {e}")
        return {"response": "–ö–µ—à—ñ—Ä—ñ“£—ñ–∑, “õ–∞–∑—ñ—Ä –±–∞–π–ª–∞–Ω—ã—Å –æ—Ä–Ω–∞—Ç—É –º“Ø–º–∫—ñ–Ω –±–æ–ª–º–∞–¥—ã. –°–µ—Ä–≤–µ—Ä–¥—ñ —Ç–µ–∫—Å–µ—Ä—ñ–ø –∫”©—Ä—ñ“£—ñ–∑."}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
